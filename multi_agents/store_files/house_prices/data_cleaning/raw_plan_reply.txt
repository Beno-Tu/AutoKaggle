Fantastic! With the detailed information and the list of available tools, we can now create a clear and specific plan for the Data Cleaning phase. We'll break down the process into four essential tasks, ensuring each step is well-defined and actionable.

### Data Cleaning Plan

#### **Task 1: Handle Missing Values**

**Objective:** Address missing values in the dataset using appropriate imputation techniques.

**Essential Actions:**
1. **Identify Columns with Missing Values:**
   - Use pandas to identify columns with missing values in both `train.csv` and `test.csv`.
   - Calculate the percentage of missing values for each column.

2. **Impute Missing Values:**
   - For numerical columns with missing values:
     - Use `fill_missing_values` with the `mean` method for columns with less than 30% missing.
     - Use `fill_missing_values` with the `median` method for columns with 30-50% missing.
     - Use `remove_columns_with_missing_data` for columns with more than 50% missing.
   - For categorical columns with missing values:
     - Use `fill_missing_values` with the `mode` method for columns with less than 30% missing.
     - Use `fill_missing_values` with a constant value (e.g., 'None' or 'Missing') for columns with 30-50% missing.
     - Use `remove_columns_with_missing_data` for columns with more than 50% missing.

**Features Involved:**
- **Numerical:** LotFrontage, MasVnrArea, GarageYrBlt, etc.
- **Categorical:** Alley, PoolQC, Fence, MiscFeature, etc.

**Tools and Parameters:**
- `fill_missing_values(data, columns, method)`
- `remove_columns_with_missing_data(data, thresh)`

**Expected Output:**
- Cleaned data with no missing values, ready for further analysis.

**Constraints:**
- Ensure consistency in imputation methods across both `train.csv` and `test.csv`.

#### **Task 2: Detect and Handle Outliers**

**Objective:** Identify and manage outliers in numerical features to ensure data quality.

**Essential Actions:**
1. **Detect Outliers:**
   - Use `detect_and_handle_outliers_iqr` to identify outliers in numerical columns.
   - Set the `factor` parameter to 1.5 to detect moderate outliers.

2. **Handle Outliers:**
   - Use the `clip` method to cap outliers at the 1.5*IQR range.
   - For extremely skewed distributions, consider using the `remove` method, but ensure not to remove data from `test.csv`.

**Features Involved:**
- **Numerical:** LotArea, GrLivArea, TotalBsmtSF, etc.

**Tools and Parameters:**
- `detect_and_handle_outliers_iqr(data, columns, factor, method)`

**Expected Output:**
- Data with outliers appropriately handled, minimizing skewness.

**Constraints:**
- Avoid removing rows from `test.csv` to maintain data integrity.

#### **Task 3: Ensure Data Consistency**

**Objective:** Verify and ensure consistency across both `train.csv` and `test.csv`.

**Essential Actions:**
1. **Uniform Data Types:**
   - Use `convert_data_types` to ensure consistent data types for each feature.
   - Convert categorical features to `str` and numerical features to `int` or `float` as appropriate.

2. **Remove Duplicates:**
   - Use `remove_duplicates` to eliminate duplicate rows.
   - Apply this to both `train.csv` and `test.csv` to maintain consistency.

**Features Involved:**
- All features, ensuring uniformity across the dataset.

**Tools and Parameters:**
- `convert_data_types(data, columns, target_type)`
- `remove_duplicates(data, columns, keep)`

**Expected Output:**
- Consistent and clean data across both `train.csv` and `test.csv`.

**Constraints:**
- Ensure no data loss during type conversion and duplication removal.

#### **Task 4: Prepare Cleaned Datasets**

**Objective:** Save the cleaned datasets for further analysis and modeling.

**Essential Actions:**
1. **Export Cleaned Data:**
   - Use pandas to export the cleaned `train.csv` and `test.csv` datasets.
   - Save the files as `cleaned_train.csv` and `cleaned_test.csv`.

**Features Involved:**
- All features, ensuring a comprehensive cleaned dataset.

**Tools and Parameters:**
- `pd.to_csv('cleaned_train.csv')`
- `pd.to_csv('cleaned_test.csv')`

**Expected Output:**
- Cleaned datasets saved as `cleaned_train.csv` and `cleaned_test.csv`.

**Constraints:**
- Ensure no data corruption during the export process.

### Summary
By following these four well-defined tasks, you'll achieve a clean and consistent dataset ready for the next phases of analysis and modeling. Each task is tailored to address specific issues identified in the preliminary EDA phase and aligned with the available tools and resources.