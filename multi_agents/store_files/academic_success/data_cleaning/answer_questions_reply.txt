Let's summarize the Data Cleaning phase based on the provided information.

### Question 1
**What specific missing values were addressed during the data cleaning process, and what imputation methods were used for both numerical and categorical features?**

- **Numerical Features:** The following features were addressed using the median for imputation:
  - Previous qualification (grade)
  - Admission grade
  - Curricular units (credited/enrolled/evaluations/approved/grade for both semesters)
  - Unemployment rate
  - Inflation rate
  - GDP
  
- **Categorical Features:** The following features were addressed using the mode for imputation:
  - Marital status
  - Application mode
  - Course
  - Previous qualification
  - Nationality
  - Mother's qualification
  - Father's qualification
  - Mother's occupation
  - Father's occupation
  - Displaced
  - Educational special needs
  - Debtor
  - Tuition fees up to date
  - Gender
  - Scholarship holder
  - International

### Question 2
**Which features were removed due to excessive missing values, and what was the rationale behind the chosen threshold?**

- Features with more than 60% missing values were removed. This threshold was chosen to minimize noise and potential biases introduced by features that contain inadequate information for analysis and modeling.

### Question 3
**What outlier handling methods were applied, and how did these methods affect the distribution of numerical features?**

- Outliers were handled using the IQR (Interquartile Range) method with a factor of 1.5, where outlier values were clipped. This method capped extreme values at the upper and lower bounds, enhancing the robustness of the numerical features while preserving the overall distribution without dramatically compressing feature ranges.

### Question 4
**How were categorical features standardized, and what common issues (e.g., typos, case sensitivity) were corrected?**

- Categorical features were standardized by:
  - Converting all strings to lowercase.
  - Stripping leading and trailing whitespaces.
  - Placeholder for correcting common typos based on predefined mappings (not yet implemented).
  
This approach helped eliminate discrepancies due to case sensitivity and unwanted spaces.

### Question 5
**What were the outcomes of the duplicate removal process, and how many duplicate rows were identified and eliminated?**

- The duplicate removal step ensured that all rows, except the unique identifier (`id`), were checked for duplicates. The exact number of duplicates eliminated was not specified in the output, but this process ensures that each `id` remains unique.

### Question 6
**What insights or patterns emerged during the data cleaning phase that should be explored further in the In-depth Exploratory Data Analysis?**

- While there were no visual insights provided from this phase, the handling of missing values and outliers may indicate areas of interest in the data distribution and relationships between features. It would be beneficial to explore how these cleaned features correlate with the target variable (academic risk classification) in the next exploratory analysis phase.

---

This detailed summary encapsulates the important aspects of the Data Cleaning phase, setting the stage for the next steps in your analysis process.